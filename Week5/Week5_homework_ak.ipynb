{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-04 22:04:58--  https://nyc-tlc.s3.amazonaws.com/trip+data/fhvhv_tripdata_2021-02.csv\n",
      "Resolving nyc-tlc.s3.amazonaws.com (nyc-tlc.s3.amazonaws.com)... 52.217.76.236\n",
      "Connecting to nyc-tlc.s3.amazonaws.com (nyc-tlc.s3.amazonaws.com)|52.217.76.236|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 733822658 (700M) [text/csv]\n",
      "Saving to: ‘/Users/amey/git/data-engineering-zoomcamp-amey/5_Week_5_batch_processing/Spark/fhvhv_tripdata_2021-02.csv’\n",
      "\n",
      "fhvhv_tripdata_2021 100%[===================>] 699.83M  28.9MB/s    in 23s     \n",
      "\n",
      "2022-03-04 22:05:22 (30.0 MB/s) - ‘/Users/amey/git/data-engineering-zoomcamp-amey/5_Week_5_batch_processing/Spark/fhvhv_tripdata_2021-02.csv’ saved [733822658/733822658]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://nyc-tlc.s3.amazonaws.com/trip+data/fhvhv_tripdata_2021-02.csv -P \"/Users/amey/git/data-engineering-zoomcamp-amey/5_Week_5_batch_processing/Spark/homework\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11613943 fhvhv_tripdata_2021-02.csv\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l fhvhv_tripdata_2021-02.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField('hvfhs_license_num',types.StringType(),True),\n",
    "    types.StructField('dispatching_base_num',types.StringType(),True),\n",
    "    types.StructField('pickup_datetime',types.TimestampType(),True),\n",
    "    types.StructField('dropoff_datetime',types.TimestampType(),True),\n",
    "    types.StructField('PULocationID',types.IntegerType(),True),\n",
    "    types.StructField('DOLocationID',types.IntegerType(),True),\n",
    "    types.StructField('SR_Flag',types.StringType(),True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\",\"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv('/Users/amey/git/data-engineering-zoomcamp-amey/5_Week_5_batch_processing/Spark/homework/fhvhv_tripdata_2021-02.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(24) #partitioning file into smaller chuncks so that executors in spark cluster can process file efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.parquet('/Users/amey/git/data-engineering-zoomcamp-amey/5_Week_5_batch_processing/Spark/homework/fhvhvparquet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parquet = spark.read.parquet('/Users/amey/git/data-engineering-zoomcamp-amey/5_Week_5_batch_processing/Spark/homework/fhvhvparquet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parquet.registerTempTable('fhvhv_feb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3\n",
    "df_Q3 = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    \n",
    "    COUNT(1) AS number_records\n",
    "    \n",
    "FROM\n",
    "    fhvhv_feb\n",
    "\n",
    "WHERE pickup_datetime between '2021-02-15 00:00:00' and '2021-02-15 23:59:59'\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|number_records|\n",
      "+--------------+\n",
      "|        367170|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_Q3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------------------+\n",
      "|    pickup_datetime|   dropoff_datetime|           trip_time|\n",
      "+-------------------+-------------------+--------------------+\n",
      "|2021-02-11 13:40:44|2021-02-12 10:39:44|INTERVAL '0 20:59...|\n",
      "|2021-02-17 15:54:53|2021-02-18 07:48:34|INTERVAL '0 15:53...|\n",
      "|2021-02-20 12:08:15|2021-02-21 00:22:14|INTERVAL '0 12:13...|\n",
      "|2021-02-03 20:24:25|2021-02-04 07:41:58|INTERVAL '0 11:17...|\n",
      "|2021-02-19 23:17:44|2021-02-20 09:44:01|INTERVAL '0 10:26...|\n",
      "|2021-02-25 17:13:35|2021-02-26 02:57:05|INTERVAL '0 09:43...|\n",
      "|2021-02-20 01:36:13|2021-02-20 11:16:19|INTERVAL '0 09:40...|\n",
      "|2021-02-18 15:24:19|2021-02-19 01:01:11|INTERVAL '0 09:36...|\n",
      "|2021-02-18 01:31:20|2021-02-18 11:07:15|INTERVAL '0 09:35...|\n",
      "|2021-02-10 20:51:39|2021-02-11 06:21:08|INTERVAL '0 09:29...|\n",
      "|2021-02-10 01:56:17|2021-02-10 10:57:33|INTERVAL '0 09:01...|\n",
      "|2021-02-25 09:18:18|2021-02-25 18:18:57|INTERVAL '0 09:00...|\n",
      "|2021-02-21 19:59:13|2021-02-22 04:56:16|INTERVAL '0 08:57...|\n",
      "|2021-02-09 18:36:13|2021-02-10 03:31:00|INTERVAL '0 08:54...|\n",
      "|2021-02-06 09:48:09|2021-02-06 18:32:16|INTERVAL '0 08:44...|\n",
      "|2021-02-02 09:42:30|2021-02-02 18:17:43|INTERVAL '0 08:35...|\n",
      "|2021-02-10 10:12:08|2021-02-10 18:46:24|INTERVAL '0 08:34...|\n",
      "|2021-02-09 13:30:13|2021-02-09 22:02:25|INTERVAL '0 08:32...|\n",
      "|2021-02-21 22:50:52|2021-02-22 07:21:52|INTERVAL '0 08:31...|\n",
      "|2021-02-05 21:32:33|2021-02-06 06:01:04|INTERVAL '0 08:28...|\n",
      "+-------------------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Q4\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    \n",
    "    pickup_datetime,\n",
    "    dropoff_datetime,\n",
    "    (dropoff_datetime - pickup_datetime) as trip_time\n",
    "    \n",
    "FROM\n",
    "    fhvhv_feb\n",
    "\n",
    "GROUP BY 1,2,3\n",
    "ORDER BY 3 DESC\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|dispatching_base_num|num_of_trips|\n",
      "+--------------------+------------+\n",
      "|              B02510|     3233664|\n",
      "|              B02764|      965568|\n",
      "|              B02872|      882689|\n",
      "|              B02875|      685390|\n",
      "|              B02765|      559768|\n",
      "|              B02869|      429720|\n",
      "|              B02887|      322331|\n",
      "|              B02871|      312364|\n",
      "|              B02864|      311603|\n",
      "|              B02866|      311089|\n",
      "|              B02878|      305185|\n",
      "|              B02682|      303255|\n",
      "|              B02617|      274510|\n",
      "|              B02883|      251617|\n",
      "|              B02884|      244963|\n",
      "|              B02882|      232173|\n",
      "|              B02876|      215693|\n",
      "|              B02879|      210137|\n",
      "|              B02867|      200530|\n",
      "|              B02877|      198938|\n",
      "+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Q5\n",
    "spark.sql(\"\"\"\n",
    "SELECT \n",
    "    \n",
    "    dispatching_base_num,\n",
    "    COUNT(1) as num_of_trips\n",
    "    \n",
    "FROM\n",
    "    fhvhv_feb\n",
    "\n",
    "GROUP BY 1\n",
    "ORDER BY 2 DESC\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-04 23:07:33--  https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.136.48\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.136.48|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12322 (12K) [application/octet-stream]\n",
      "Saving to: ‘/Users/amey/git/data-engineering-zoomcamp-amey/5_Week_5_batch_processing/Spark/homework/taxi+_zone_lookup.csv’\n",
      "\n",
      "taxi+_zone_lookup.c 100%[===================>]  12.03K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2022-03-04 23:07:33 (17.5 MB/s) - ‘/Users/amey/git/data-engineering-zoomcamp-amey/5_Week_5_batch_processing/Spark/homework/taxi+_zone_lookup.csv’ saved [12322/12322]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv -P \"/Users/amey/git/data-engineering-zoomcamp-amey/5_Week_5_batch_processing/Spark/homework\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones_schema=types.StructType([\n",
    "    types.StructField(\"LocationID\",types.IntegerType(),True),\n",
    "    types.StructField(\"Borough\",types.StringType(),True),\n",
    "    types.StructField(\"Zone\",types.StringType(),True),\n",
    "    types.StructField(\"service_zone\",types.StringType(),True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read \\\n",
    "    .option(\"header\",\"true\") \\\n",
    "    .schema(zones_schema) \\\n",
    "    .csv('/Users/amey/git/data-engineering-zoomcamp-amey/5_Week_5_batch_processing/Spark/homework/taxi+_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = df_zones.repartition(4) #partitioning file into smaller chuncks so that executors in spark cluster can process file efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones.write.parquet('/Users/amey/git/data-engineering-zoomcamp-amey/5_Week_5_batch_processing/Spark/homework/zonesparquet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones_parquet = spark.read.parquet('/Users/amey/git/data-engineering-zoomcamp-amey/5_Week_5_batch_processing/Spark/homework/zonesparquet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LocationID: integer (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zones_parquet.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones_parquet.registerTempTable('zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "| Pickup_Dropoff_Zone|num_of_trips|\n",
      "+--------------------+------------+\n",
      "|East New York/Eas...|       45041|\n",
      "|Borough Park/Boro...|       37329|\n",
      "|   Canarsie/Canarsie|       28026|\n",
      "|Crown Heights Nor...|       25976|\n",
      "| Bay Ridge/Bay Ridge|       17934|\n",
      "|Jackson Heights/J...|       14688|\n",
      "|     Astoria/Astoria|       14688|\n",
      "|Central Harlem No...|       14481|\n",
      "|Bushwick South/Bu...|       14424|\n",
      "|Flatbush/Ditmas P...|       13976|\n",
      "|South Ozone Park/...|       13716|\n",
      "|Brownsville/Brown...|       12829|\n",
      "|      JFK Airport/NA|       12542|\n",
      "|Prospect-Lefferts...|       11814|\n",
      "|Forest Hills/Fore...|       11548|\n",
      "|Bushwick North/Bu...|       11491|\n",
      "|Bushwick South/Bu...|       11487|\n",
      "|Crown Heights Nor...|       11462|\n",
      "|Crown Heights Nor...|       11342|\n",
      "|Prospect-Lefferts...|       11308|\n",
      "+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Q6\n",
    "df_fhvhv_zones=spark.sql(\"\"\"\n",
    "SELECT \n",
    "    \n",
    "    cast(b.Zone ||'/'|| c.Zone as CHAR(100)) as Pickup_Dropoff_Zone,\n",
    "    count(1) as num_of_trips\n",
    "    \n",
    "    \n",
    "FROM fhvhv_feb a\n",
    "\n",
    "LEFT JOIN zones b\n",
    "on a.PULocationID = b.LocationID\n",
    "\n",
    "LEFT JOIN zones c\n",
    "on a.DOLocationID = c.LocationID\n",
    "\n",
    "GROUP BY 1\n",
    "ORDER BY 2 DESC\n",
    "\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6 - second option\n",
    "df_Q6_option2=spark.sql(\"\"\"\n",
    "SELECT \n",
    "    \n",
    "    PULocationID,\n",
    "    DOLocationID,\n",
    "    count(1) as num_of_trips\n",
    "    \n",
    "    \n",
    "FROM fhvhv_feb a\n",
    "\n",
    "GROUP BY 1,2\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones_parquet_tmp1 = df_zones_parquet \\\n",
    "                        .withColumnRenamed('LocationID', 'PULocationID')\n",
    "\n",
    "df_zones_parquet_tmp2 = df_zones_parquet \\\n",
    "                        .withColumnRenamed('LocationID', 'DOLocationID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------+---------+--------------------+------------+---------+--------------------+------------+\n",
      "|DOLocationID|PULocationID|num_of_trips|  Borough|                Zone|service_zone|  Borough|                Zone|service_zone|\n",
      "+------------+------------+------------+---------+--------------------+------------+---------+--------------------+------------+\n",
      "|          76|          76|       45041| Brooklyn|       East New York|   Boro Zone| Brooklyn|       East New York|   Boro Zone|\n",
      "|          26|          26|       37329| Brooklyn|        Borough Park|   Boro Zone| Brooklyn|        Borough Park|   Boro Zone|\n",
      "|          39|          39|       28026| Brooklyn|            Canarsie|   Boro Zone| Brooklyn|            Canarsie|   Boro Zone|\n",
      "|          61|          61|       25976| Brooklyn| Crown Heights North|   Boro Zone| Brooklyn| Crown Heights North|   Boro Zone|\n",
      "|          14|          14|       17934| Brooklyn|           Bay Ridge|   Boro Zone| Brooklyn|           Bay Ridge|   Boro Zone|\n",
      "|           7|           7|       14688|   Queens|             Astoria|   Boro Zone|   Queens|             Astoria|   Boro Zone|\n",
      "|         129|         129|       14688|   Queens|     Jackson Heights|   Boro Zone|   Queens|     Jackson Heights|   Boro Zone|\n",
      "|          42|          42|       14481|Manhattan|Central Harlem North|   Boro Zone|Manhattan|Central Harlem North|   Boro Zone|\n",
      "|          37|          37|       14424| Brooklyn|      Bushwick South|   Boro Zone| Brooklyn|      Bushwick South|   Boro Zone|\n",
      "|          89|          89|       13976| Brooklyn|Flatbush/Ditmas Park|   Boro Zone| Brooklyn|Flatbush/Ditmas Park|   Boro Zone|\n",
      "|         216|         216|       13716|   Queens|    South Ozone Park|   Boro Zone|   Queens|    South Ozone Park|   Boro Zone|\n",
      "|          35|          35|       12829| Brooklyn|         Brownsville|   Boro Zone| Brooklyn|         Brownsville|   Boro Zone|\n",
      "|         265|         132|       12542|   Queens|         JFK Airport|    Airports|  Unknown|                  NA|         N/A|\n",
      "|          61|         188|       11814| Brooklyn|Prospect-Lefferts...|   Boro Zone| Brooklyn| Crown Heights North|   Boro Zone|\n",
      "|          95|          95|       11548|   Queens|        Forest Hills|   Boro Zone|   Queens|        Forest Hills|   Boro Zone|\n",
      "|          37|          36|       11491| Brooklyn|      Bushwick North|   Boro Zone| Brooklyn|      Bushwick South|   Boro Zone|\n",
      "|          36|          37|       11487| Brooklyn|      Bushwick South|   Boro Zone| Brooklyn|      Bushwick North|   Boro Zone|\n",
      "|         188|          61|       11462| Brooklyn| Crown Heights North|   Boro Zone| Brooklyn|Prospect-Lefferts...|   Boro Zone|\n",
      "|         225|          61|       11342| Brooklyn| Crown Heights North|   Boro Zone| Brooklyn|  Stuyvesant Heights|   Boro Zone|\n",
      "|         188|         188|       11308| Brooklyn|Prospect-Lefferts...|   Boro Zone| Brooklyn|Prospect-Lefferts...|   Boro Zone|\n",
      "+------------+------------+------------+---------+--------------------+------------+---------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_Q6_option2.join(df_zones_parquet_tmp1, ['PULocationID'], \"left\") \\\n",
    "             .join(df_zones_parquet_tmp2, ['DOLocationID'], \"left\") \\\n",
    "             .sort(df_Q6_option2.num_of_trips.desc()) \\\n",
    "             .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-99-30ea790be275>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-99-30ea790be275>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    df_Q6_option2.as(\"a\").join(df_zones_parquet.as(\"b\"), $\"a.PULocationID\" == $\"b.LocationID\", \"left\") \\\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#***Does not work***\n",
    "df_Q6_option2.as(\"a\").join(df_zones_parquet.as(\"b\"), $\"a.PULocationID\" == $\"b.LocationID\", \"left\") \\\n",
    "                     .join(df_zones_parquet.as(\"c\"), $\"a.DOLocationID\" == $\"c.LocationID\", \"left\") \\\n",
    "                     .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "SparkSession.stop(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
